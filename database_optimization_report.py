#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®åº“æ™ºèƒ½ä¼˜åŒ–åˆ†ææŠ¥å‘Šç”Ÿæˆå™¨
åŸºäºOracle AWRæŠ¥å‘Šé£æ ¼ï¼Œç”Ÿæˆä¸“ä¸šçš„MySQLæ•°æ®åº“ä¼˜åŒ–åˆ†ææŠ¥å‘Š
"""

import json
import os
import re
import sys
from datetime import datetime
from typing import Dict, List, Optional
from collections import defaultdict
from docx import Document
from docx.shared import Inches, Pt, RGBColor, Cm, Mm
from docx.enum.text import WD_ALIGN_PARAGRAPH, WD_COLOR_INDEX, WD_BREAK
from docx.oxml.shared import OxmlElement, qn
from docx.oxml.ns import nsdecls

# å¯¼å…¥æ‹†åˆ†åçš„æ¨¡å—
from utils import setup_encoding, load_db_config
from data_masking import DataMasking
from sql_analyzer import SQLAnalyzer
from data_processor import DataProcessor
from database_helper import DatabaseHelper
from summary_generator import SummaryGenerator
from report_generator import ReportGenerator
from report_generator_core import ReportGeneratorCore

# è®¾ç½®ç¼–ç 
setup_encoding()

# æ·»åŠ å¿…è¦çš„å¯¼å…¥
from analyze_slow_queries import SlowQueryAnalyzer

# å°è¯•å¯¼å…¥æ™ºèƒ½ä¼˜åŒ–å»ºè®®æ¨¡å—ï¼ˆå¯é€‰ï¼‰
try:
    from intelligent_optimization_suggestions import IntelligentOptimizationSuggestions
    INTELLIGENT_OPTIMIZER_AVAILABLE = True
except ImportError:
    INTELLIGENT_OPTIMIZER_AVAILABLE = False
    IntelligentOptimizationSuggestions = None

class DatabaseOptimizationReport:
    """æ•°æ®åº“æ™ºèƒ½ä¼˜åŒ–åˆ†ææŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, use_live_analysis: bool = False, 
                 slow_query_db_config: Dict = None,  # type: ignore
                 business_db_config: Dict = None,  # type: ignore
                 min_execute_cnt: int = 1000,
                 min_query_time: float = 10.0,
                 load_data: bool = True):
        self.slow_query_db_config = slow_query_db_config
        self.business_db_config = business_db_config
        self.analysis_data = None
        self.compare_data = None
        self.use_live_analysis = use_live_analysis
        # å®šä¹‰éœ€è¦æ’é™¤çš„è¡¨ååˆ—è¡¨
        self.excluded_tables = ['test_table_0']
        
        # åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨
        self.report_generator = ReportGenerator(
            db_connection_manager=business_db_config,
            excluded_tables=self.excluded_tables
        )
        
        # åˆå§‹åŒ–æ…¢æŸ¥è¯¢æ•°æ®åº“è¿æ¥é…ç½®
        self.slow_query_db_host = slow_query_db_config.get('host', '127.0.0.1') if slow_query_db_config else '127.0.0.1'
        self.slow_query_db_user = slow_query_db_config.get('user', 'test') if slow_query_db_config else 'test'
        self.slow_query_db_password = slow_query_db_config.get('password', 'test') if slow_query_db_config else 'test'
        self.slow_query_db_port = slow_query_db_config.get('port', 3306) if slow_query_db_config else 3306
        
        # åˆå§‹åŒ–ä¸šåŠ¡æ•°æ®åº“è¿æ¥é…ç½®ï¼ˆç”¨äºæŸ¥è¯¢å®é™…æ…¢æŸ¥è¯¢çš„æ•°æ®åº“ï¼‰
        self.business_db_host = business_db_config.get('host', '127.0.0.1') if business_db_config else '127.0.0.1'
        self.business_db_user = business_db_config.get('user', 'test') if business_db_config else 'test'
        self.business_db_password = business_db_config.get('password', 'test') if business_db_config else 'test'
        self.business_db_port = business_db_config.get('port', 3306) if business_db_config else 3306
        
        # åˆå§‹åŒ–æ¨¡å—å®ä¾‹
        self.db_helper = DatabaseHelper(
            business_db_config=business_db_config,
            slow_query_db_config=slow_query_db_config
        )

        # æ˜¯å¦å¯ç”¨æ–°çš„æ™ºèƒ½ä¼˜åŒ–å»ºè®®æ¨¡å—ï¼ˆé»˜è®¤å…³é—­ï¼Œä¿æŒæ‹†åˆ†å‰è¾“å‡ºï¼‰
        self.enable_intelligent_optimizer = False
        
        # åˆå§‹åŒ–æ™ºèƒ½ä¼˜åŒ–å»ºè®®ç”Ÿæˆå™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if INTELLIGENT_OPTIMIZER_AVAILABLE and IntelligentOptimizationSuggestions:
            try:
                self.intelligent_optimizer = IntelligentOptimizationSuggestions(
                    db_helper=self.db_helper
                )
            except Exception:
                self.intelligent_optimizer = None
        else:
            self.intelligent_optimizer = None
        
        if not load_data:
            # ä¸åŠ è½½å¤–éƒ¨æ•°æ®ï¼Œä»…ç”¨äºæµ‹è¯•
            return
            
        if use_live_analysis and slow_query_db_config:
            # ä½¿ç”¨å®æ—¶åˆ†æ
            self._perform_live_analysis(slow_query_db_config, min_execute_cnt, min_query_time)

    def _perform_live_analysis(self, db_config: Dict, min_execute_cnt: int, min_query_time: float):
        """æ‰§è¡Œå®æ—¶æ…¢æŸ¥è¯¢åˆ†æï¼ŒåŒ…æ‹¬å¯¹æ¯”åˆ†æ"""
        try:
            # åˆ›å»ºæ…¢æŸ¥è¯¢åˆ†æå™¨ï¼Œä¼ å…¥è¡¨åé…ç½®
            if not db_config:
                raise ValueError("æ•°æ®åº“é…ç½®ä¸èƒ½ä¸ºç©º")
            
            analyzer = SlowQueryAnalyzer(
                slow_query_db_host=db_config.get('host', ''),
                slow_query_db_user=db_config.get('user', ''),
                slow_query_db_password=db_config.get('password', ''),
                slow_query_db_port=db_config.get('port', 3306),
                slow_query_db_name=db_config.get('database', ''),
                slow_query_table=db_config.get('table', 'slow'),
                business_db_config=self.business_db_config
            )
            
            # æ‰§è¡Œå¯¹æ¯”åˆ†æ
            compare_result = analyzer.compare_slow_queries(min_execute_cnt, min_query_time)
            
            # è¿‡æ»¤æ‰åŒ…å«æ’é™¤è¡¨åçš„æŸ¥è¯¢
            if compare_result:
                # è¿‡æ»¤ä¸Šä¸ªæœˆçš„æ•°æ®
                if 'last_month' in compare_result and 'queries' in compare_result['last_month']:
                    original_last_month_count = len(compare_result['last_month']['queries'])
                    compare_result['last_month']['queries'] = DataProcessor.filter_excluded_tables(
                        compare_result['last_month']['queries'], 
                        self.excluded_tables
                    )
                
                # è¿‡æ»¤å‰ä¸€ä¸ªæœˆçš„æ•°æ®
                if 'previous_month' in compare_result and 'queries' in compare_result['previous_month']:
                    original_prev_month_count = len(compare_result['previous_month']['queries'])
                    compare_result['previous_month']['queries'] = DataProcessor.filter_excluded_tables(
                        compare_result['previous_month']['queries'],
                        self.excluded_tables
                    )
            
            # ä¸æ‰“å°ä»»ä½•æ…¢æŸ¥è¯¢SQLï¼Œç¬¦åˆç”¨æˆ·è¦æ±‚
            # åŸä»£ç å·²æ³¨é‡Šæ‰
            
            # æ›´æ–°åˆ†ææ•°æ®
            self.compare_data = compare_result
            
            if compare_result:
                # å¯¹æ•°æ®è¿›è¡Œè„±æ•å¤„ç†
                self.compare_data = compare_result
                
                # åªä¿ç•™ä¸Šä¸ªæœˆçš„æ…¢æŸ¥è¯¢æ•°æ®ï¼Œé¿å…é‡å¤ç»Ÿè®¡
                self.analysis_data = []
                # åªæ·»åŠ ä¸Šä¸ªæœˆçš„æ•°æ®ï¼ˆå½“å‰éœ€è¦åˆ†æçš„æ…¢æŸ¥è¯¢ï¼‰
                if 'queries' in compare_result['last_month']:
                    self.analysis_data.extend(compare_result['last_month']['queries'])
            else:
                # æ²¡æœ‰è·å–åˆ°çœŸå®æ•°æ®æ—¶æŠ›å‡ºé”™è¯¯
                if not self.analysis_data:
                    raise Exception("å®æ—¶åˆ†æå¤±è´¥ï¼Œæ— æ³•è·å–çœŸå®çš„æ…¢æŸ¥è¯¢æ•°æ®")
        
        except Exception as e:
            # æ²¡æœ‰è·å–åˆ°çœŸå®æ•°æ®æ—¶æŠ›å‡ºé”™è¯¯
            if not self.analysis_data:
                raise Exception(f"å®æ—¶åˆ†æå¤±è´¥: {str(e)}")
        
    def _mask_sensitive_data(self, data: List[Dict]) -> List[Dict]:
        """å¯¹æ•æ„Ÿä¿¡æ¯è¿›è¡Œè„±æ•å¤„ç†"""
        return DataMasking.mask_sensitive_data(data)
    
    # åŒ…è£…æ–¹æ³•ï¼šè°ƒç”¨æ–°æ¨¡å—çš„æ–¹æ³•ä»¥ä¿æŒå‘åå…¼å®¹
    def _mask_db_name(self, db_name) -> str:
        """è„±æ•æ•°æ®åº“åï¼ˆåŒ…è£…æ–¹æ³•ï¼‰"""
        return DataMasking.mask_db_name(db_name)
    
    def _mask_ip(self, ip) -> str:
        """è„±æ•IPåœ°å€ï¼ˆåŒ…è£…æ–¹æ³•ï¼‰"""
        return DataMasking.mask_ip(ip)
    
    def _mask_table_name(self, table_name) -> str:
        """è„±æ•è¡¨åï¼ˆåŒ…è£…æ–¹æ³•ï¼‰"""
        return DataMasking.mask_table_name(table_name)
    
    def _mask_sql(self, sql) -> str:
        """è„±æ•SQLè¯­å¥ï¼ˆåŒ…è£…æ–¹æ³•ï¼‰"""
        return DataMasking.mask_sql(sql)
        
    def _extract_table_name(self, sql: str) -> Optional[str]:
        """ä»SQLè¯­å¥ä¸­æå–è¡¨åï¼ˆåŒ…è£…æ–¹æ³•ï¼‰"""
        return SQLAnalyzer.extract_table_name(sql)

    def _extract_where_fields(self, sql: str) -> List[str]:
        """ä»SQLè¯­å¥ä¸­æå–WHEREæ¡ä»¶ä¸­çš„å­—æ®µåï¼ˆåŒ…è£…æ–¹æ³•ï¼‰"""
        return SQLAnalyzer.extract_where_fields(sql)
    
    def _extract_fields_from_condition(self, condition: str) -> List[str]:
        """ä»å•ä¸ªæ¡ä»¶ä¸­æå–å­—æ®µåï¼ˆåŒ…è£…æ–¹æ³•ï¼‰"""
        return SQLAnalyzer.extract_fields_from_condition(condition)
    
    def _extract_join_fields(self, sql: str) -> List[str]:
        """ä»SQLè¯­å¥ä¸­æå–JOINæ¡ä»¶ä¸­çš„å­—æ®µåï¼ˆåŒ…è£…æ–¹æ³•ï¼‰"""
        return SQLAnalyzer.extract_join_fields(sql)
    
    def _extract_order_by_fields(self, sql: str) -> List[str]:
        """ä»SQLè¯­å¥ä¸­æå–ORDER BYå­å¥ä¸­çš„å­—æ®µåï¼ˆåŒ…è£…æ–¹æ³•ï¼‰"""
        return SQLAnalyzer.extract_order_by_fields(sql)
    
    def _sort_fields_by_priority(self, fields: List[str], sql_lower: str) -> List[str]:
        """æ™ºèƒ½æ’åºå­—æ®µä¼˜å…ˆçº§ï¼ˆåŒ…è£…æ–¹æ³•ï¼‰"""
        return SQLAnalyzer.sort_fields_by_priority(fields, sql_lower)
    
    
    def _get_standby_hostname(self, master_hostname: str) -> Optional[str]:
        """é€šè¿‡clusterè¡¨æŸ¥è¯¢è·å–å¤‡åº“IPåœ°å€ï¼ˆåŒ…è£…æ–¹æ³•ï¼‰"""
        return self.db_helper.get_standby_hostname(master_hostname)

    def _get_safe_connection(self, hostname: str = None, database: str = None) -> dict:
        """å®‰å…¨åœ°è·å–æ•°æ®åº“è¿æ¥ï¼ˆåŒ…è£…æ–¹æ³•ï¼‰"""
        return self.db_helper.get_safe_connection(hostname, database)
    
    def _close_safe_connection(self):
        """å®‰å…¨å…³é—­æ•°æ®åº“è¿æ¥ï¼ˆåŒ…è£…æ–¹æ³•ï¼‰"""
        self.db_helper.close_safe_connection()
    
    def _execute_safe_query(self, query: str, params: tuple = None, hostname: str = None, database: str = None) -> dict:
        """å®‰å…¨æ‰§è¡Œæ•°æ®åº“æŸ¥è¯¢ï¼ˆåŒ…è£…æ–¹æ³•ï¼‰"""
        return self.db_helper.execute_safe_query(query, params, hostname, database)
    
    def _get_table_row_count(self, database: str, table_name: str, hostname: str = None) -> Optional[int]:
        """
        è·å–è¡¨çš„è¡Œæ•°ï¼ˆä½¿ç”¨hostname_maxè¿æ¥çœŸå®ä¸šåŠ¡æ•°æ®åº“ï¼‰
        """
        if not table_name:
            return None
        
        actual_database = database
        if database:
            if not self.db_helper.check_table_exists(database, table_name, hostname):
                found_database = self.db_helper.find_correct_database_for_table(table_name, hostname)
                if found_database:
                    actual_database = found_database
                    print(f"â„¹ï¸ æ‰¾åˆ°è¡¨ {table_name} æ‰€åœ¨çš„å®é™…æ•°æ®åº“: {actual_database} (hostname: {hostname})")
                else:
                    print(f"âš ï¸ æ— æ³•æ‰¾åˆ°è¡¨ {table_name} æ‰€åœ¨çš„æ•°æ®åº“ï¼Œä½¿ç”¨ä¼ å…¥çš„æ•°æ®åº“: {database}")
                    actual_database = database
        else:
            found_database = self.db_helper.find_correct_database_for_table(table_name, hostname)
            if found_database:
                actual_database = found_database
            else:
                print(f"âŒ æœªæä¾›æ•°æ®åº“åä¸”æ— æ³•æ‰¾åˆ°è¡¨ {table_name} æ‰€åœ¨çš„æ•°æ®åº“")
                return None
        
        return self.db_helper.get_table_row_count(actual_database, table_name, hostname)

    def _get_table_row_count_with_fallback(self, database: str, table_name: str, hostname: str = None, query: Optional[dict] = None) -> Optional[int]:
        """è·å–è¡¨è¡Œæ•°ï¼Œè‹¥æ•°æ®åº“æŸ¥è¯¢å¤±è´¥åˆ™å›é€€åˆ°æŸ¥è¯¢å…ƒæ•°æ®"""
        row_count = self._get_table_row_count(database, table_name, hostname)
        if row_count is None:
            row_count = self._extract_row_count_from_query(query)
        return row_count

    def _extract_row_count_from_query(self, query: Optional[dict]) -> Optional[int]:
        """ä»æŸ¥è¯¢å…ƒæ•°æ®ä¸­æå–è¡¨è¡Œæ•°"""
        if not query or not isinstance(query, dict):
            return None
        
        direct_keys = [
            'table_row_count', 'row_count', 'table_rows', 'rows',
            'TABLE_ROWS', 'TABLE_ROW_COUNT', 'TABLE_ROWS_ESTIMATE',
            'total_rows', 'row_num'
        ]
        
        def parse_value(value):
            if value is None:
                return None
            if isinstance(value, (int, float)):
                return int(value)
            if isinstance(value, str):
                cleaned = value.replace(',', '').strip()
                if not cleaned:
                    return None
                try:
                    return int(float(cleaned))
                except ValueError:
                    return None
            return None
        
        def try_extract(source):
            if not source or not isinstance(source, dict):
                return None
            for key in direct_keys:
                if key in source:
                    parsed = parse_value(source[key])
                    if parsed is not None:
                        return parsed
            return None
        
        def ensure_dict(value):
            if isinstance(value, dict):
                return value
            if isinstance(value, str):
                try:
                    import json
                    return json.loads(value)
                except Exception:
                    try:
                        import ast
                        return ast.literal_eval(value)
                    except Exception:
                        return {}
            return {}
        
        # é¡¶å±‚ç›´æ¥ä¿¡æ¯
        direct = try_extract(query)
        if direct is not None:
            return direct
        
        # table_structure ä¸­çš„ä¿¡æ¯
        table_structure = ensure_dict(query.get('table_structure', {}))
        if table_structure:
            direct = try_extract(table_structure)
            if direct is not None:
                return direct
            
            for nested_key in ['table_stats', 'statistics', 'stats', 'meta']:
                nested = ensure_dict(table_structure.get(nested_key, {}))
                direct = try_extract(nested)
                if direct is not None:
                    return direct
        
        # é¡¶å±‚å…¶ä»–ç»Ÿè®¡å­—æ®µ
        for nested_key in ['table_stats', 'statistics', 'meta']:
            nested = ensure_dict(query.get(nested_key, {}))
            direct = try_extract(nested)
            if direct is not None:
                return direct
        
        # æ…¢æŸ¥è¯¢ä¿¡æ¯ä¸­çš„ç»Ÿè®¡
        slow_info = ensure_dict(query.get('slow_query_info', {}))
        direct = try_extract(slow_info)
        if direct is not None:
            return direct
        
        for nested_key in ['table_stats', 'statistics', 'meta']:
            nested = ensure_dict(slow_info.get(nested_key, {}))
            direct = try_extract(nested)
            if direct is not None:
                return direct
        
        return None

    def _check_table_exists(self, database: str, table_name: str, hostname: str = None) -> bool:
        """æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨ï¼ˆåŒ…è£…æ–¹æ³•ï¼‰"""
        return self.db_helper.check_table_exists(database, table_name, hostname)
    
    def _get_table_indexes_from_db(self, database: str, table_name: str, hostname: str = None) -> Optional[set]:
        """ä»æ•°æ®åº“ä¸­è·å–è¡¨çš„ç´¢å¼•ä¿¡æ¯ï¼ˆåŒ…è£…æ–¹æ³•ï¼Œæ”¯æŒhostnameå‚æ•°ï¼‰"""
        result = self.db_helper.get_table_indexes_from_db(database, table_name, hostname)
        return result if result is not None else set()
    
    def _find_correct_database_for_table(self, table_name: str, hostname: Optional[str] = None) -> str:
        """
        æŸ¥æ‰¾åŒ…å«æŒ‡å®šè¡¨çš„æ­£ç¡®æ•°æ®åº“ï¼ˆä½¿ç”¨hostname_maxè¿æ¥çœŸå®ä¸šåŠ¡æ•°æ®åº“ï¼‰
        
        Args:
            table_name: è¡¨å
            hostname: ä¸»æœºåï¼ˆå¯é€‰ï¼‰ï¼Œå¦‚æœæä¾›åˆ™ä½¿ç”¨è¯¥ä¸»æœºæŸ¥æ‰¾æ•°æ®åº“ï¼ˆåº”è¯¥æ˜¯hostname_maxçš„å€¼ï¼‰
            
        Returns:
            åŒ…å«è¯¥è¡¨çš„æ•°æ®åº“åï¼Œå¦‚æœæœªæ‰¾åˆ°è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        return self.db_helper.find_correct_database_for_table(table_name, hostname)
    
    def _check_indexes_exist(self, database: str, table_name: str, where_fields: list, join_fields: list, order_by_fields: list, query: Optional[dict] = None) -> bool:
        """
        æ£€æŸ¥æ‰€æœ‰ç›¸å…³å­—æ®µæ˜¯å¦éƒ½æœ‰ç´¢å¼•
        
        Args:
            database: æ•°æ®åº“å
            table_name: è¡¨å
            where_fields: WHEREæ¡ä»¶å­—æ®µåˆ—è¡¨
            join_fields: JOINæ¡ä»¶å­—æ®µåˆ—è¡¨
            order_by_fields: ORDER BYå­—æ®µåˆ—è¡¨
            query: æŸ¥è¯¢å¯¹è±¡ï¼Œè€ƒè™‘JSONä¸­çš„è¡¨ç»“æ„ä¿¡æ¯ä½œä¸ºå‚è€ƒ
            
        Returns:
            å¦‚æœæ‰€æœ‰å­—æ®µéƒ½æœ‰ç´¢å¼•ï¼Œè¿”å›Trueï¼Œå¦åˆ™è¿”å›False
        """
        if not table_name:
            return False
        
        # ğŸ¯ å…³é”®ä¿®å¤ï¼šå¦‚æœæä¾›äº†queryå‚æ•°ä¸”åŒ…å«è¡¨ç»“æ„ä¿¡æ¯ï¼Œåˆ™è·³è¿‡è¡¨å­˜åœ¨æ€§æ£€æŸ¥
        # é¿å…åœ¨æ²¡æœ‰æ•°æ®åº“è¿æ¥çš„æƒ…å†µä¸‹è¿”å›False
        if query and isinstance(query, dict) and 'table_structure' in query:
            print(f"â„¹ï¸ ä½¿ç”¨queryå‚æ•°ä¸­çš„è¡¨ç»“æ„ä¿¡æ¯ï¼Œè·³è¿‡è¡¨å­˜åœ¨æ€§æ£€æŸ¥")
        elif database and table_name:
            # ä»queryå¯¹è±¡ä¸­è·å–hostname_maxç”¨äºè¿æ¥çœŸå®ä¸šåŠ¡æ•°æ®åº“
            hostname_max = None
            if query and isinstance(query, dict):
                slow_info = query.get('slow_query_info', {})
                hostname_max = slow_info.get('hostname_max') or slow_info.get('ip') or query.get('hostname_max') or query.get('ip')
            
            if not self._check_table_exists(database, table_name, hostname_max):
                print(f"âš ï¸ è¡¨ {table_name} åœ¨æ•°æ®åº“ {database} ä¸­ä¸å­˜åœ¨ï¼Œæ— æ³•æ£€æŸ¥ç´¢å¼•")
                return False
        
        # æ£€æŸ¥æ‰€æœ‰ç›¸å…³å­—æ®µ
        all_fields = set()
        all_fields.update([f.lower() for f in where_fields])
        all_fields.update([f.lower() for f in join_fields])
        all_fields.update([f.lower() for f in order_by_fields])
        
        if not all_fields:
            return False
        
        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šä¼˜å…ˆä»æ•°æ®åº“è¯»å–çœŸå®ç´¢å¼•ä¿¡æ¯ï¼Œå¦‚æœæ•°æ®åº“æŸ¥è¯¢å¤±è´¥ï¼Œåˆ™ä»JSONæ•°æ®ä¸­å‚è€ƒ
        existing_indexed_fields = set()
        database_query_successful = False
        
        # 1. ä¼˜å…ˆä»æ•°æ®åº“è·å–å®é™…ç´¢å¼•ä¿¡æ¯ï¼ˆä½¿ç”¨hostname_maxè¿æ¥çœŸå®ä¸šåŠ¡æ•°æ®åº“ï¼‰
        # ä»queryå¯¹è±¡æˆ–hostnameå‚æ•°ä¸­è·å–hostname_max
        if not hostname_max:
            if query and isinstance(query, dict):
                slow_info = query.get('slow_query_info', {})
                hostname_max = slow_info.get('hostname_max') or slow_info.get('ip') or query.get('hostname_max') or query.get('ip')
        
        if database and table_name:
            # ä½¿ç”¨execute_safe_queryç›´æ¥æŸ¥è¯¢ç´¢å¼•ä¿¡æ¯ï¼ˆæ”¯æŒhostnameå‚æ•°ï¼‰
            query_result = self.db_helper.execute_safe_query(
                f"SHOW INDEX FROM `{table_name}`",
                hostname=hostname_max,
                database=database
            )
            if query_result['status'] == 'success' and query_result['data']:
                # æ•°æ®åº“æŸ¥è¯¢æˆåŠŸä¸”æœ‰æ•°æ®
                for row in query_result['data']:
                    if len(row) >= 5:
                        column_name = row[4]
                        if column_name:
                            existing_indexed_fields.add(column_name.lower())
                if existing_indexed_fields:
                    database_query_successful = True
                    print(f"ğŸ“Š ä»æ•°æ®åº“è¯»å–åˆ°çš„ç´¢å¼•å­—æ®µ: {existing_indexed_fields}")
            # else:
            #     print(f"âš ï¸ æ•°æ®åº“æŸ¥è¯¢å¤±è´¥æˆ–æ— ç´¢å¼•æ•°æ®ï¼Œå°†ä»JSONæ•°æ®ä¸­å‚è€ƒ")
        
        # 2. å¦‚æœæ•°æ®åº“æŸ¥è¯¢å¤±è´¥ï¼Œä»queryå¯¹è±¡ä¸­è·å–è¡¨ç»“æ„ä¿¡æ¯ä½œä¸ºå‚è€ƒ
        if not database_query_successful and query and isinstance(query, dict) and 'table_structure' in query:
            table_structure = query.get('table_structure', {})
            # å¦‚æœtable_structureæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æ
            if isinstance(table_structure, str):
                try:
                    import json
                    table_structure = json.loads(table_structure)
                except (json.JSONDecodeError, ValueError):
                    # å¦‚æœJSONè§£æå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ast.literal_evalï¼ˆPythonå­—ç¬¦ä¸²è¡¨ç¤ºï¼‰
                    try:
                        import ast
                        table_structure = ast.literal_eval(table_structure)
                    except (ValueError, SyntaxError):
                        table_structure = {}
            
            if table_structure and isinstance(table_structure, dict) and 'indexes' in table_structure:
                indexes = table_structure['indexes']
                
                # indexeså¯èƒ½æ˜¯å­—å…¸{index_name: index_info}æˆ–åˆ—è¡¨[index_info]
                if isinstance(indexes, dict):
                    # å­—å…¸æ ¼å¼ï¼šéå†values
                    for index_info in indexes.values():
                        if isinstance(index_info, dict) and 'columns' in index_info:
                            for col in index_info['columns']:
                                existing_indexed_fields.add(col.lower())
                elif isinstance(indexes, list):
                    # åˆ—è¡¨æ ¼å¼
                    for index_info in indexes:
                        if isinstance(index_info, dict):
                            # æ”¯æŒå¤šç§ç´¢å¼•æ ¼å¼
                            if 'columns' in index_info:
                                # æ ¼å¼1: {'columns': ['id']}
                                for col in index_info['columns']:
                                    existing_indexed_fields.add(col.lower())
                            elif 'Column_name' in index_info:
                                # æ ¼å¼2: {'Column_name': 'id'} (MySQL SHOW INDEXESæ ¼å¼)
                                existing_indexed_fields.add(index_info['Column_name'].lower())
                
                if existing_indexed_fields:
                    print(f"ğŸ“‹ ä»JSONæ•°æ®ä¸­å‚è€ƒåˆ°çš„ç´¢å¼•å­—æ®µ: {existing_indexed_fields}")
        
        # 3. æ£€æŸ¥æ‰€æœ‰å­—æ®µæ˜¯å¦éƒ½æœ‰ç´¢å¼•
        if existing_indexed_fields:
            # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å­—æ®µéƒ½æœ‰å•ç‹¬çš„ç´¢å¼•
            all_fields_have_individual_indexes = True
            fields_without_individual_indexes = []
            
            for field in all_fields:
                if field not in existing_indexed_fields:
                    all_fields_have_individual_indexes = False
                    fields_without_individual_indexes.append(field)
            
            if all_fields_have_individual_indexes:
                # æ‰€æœ‰å­—æ®µéƒ½æœ‰å•ç‹¬ç´¢å¼•ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦å¤åˆç´¢å¼•
                # å¦‚æœWHEREæ¡ä»¶ä¸­æœ‰å¤šä¸ªå­—æ®µï¼Œå»ºè®®å¤åˆç´¢å¼•
                if len(where_fields) > 1:
                    print(f"â„¹ï¸ æ‰€æœ‰å­—æ®µéƒ½æœ‰å•ç‹¬ç´¢å¼•ï¼Œä½†WHEREæ¡ä»¶ä¸­æœ‰å¤šä¸ªå­—æ®µï¼Œå»ºè®®å¤åˆç´¢å¼•")
                    return False  # è¿”å›Falseè¡¨ç¤ºå»ºè®®åˆ›å»ºå¤åˆç´¢å¼•
                else:
                    print(f"âœ… æ‰€æœ‰å­—æ®µéƒ½æœ‰ç´¢å¼•ï¼Œå­—æ®µ: {all_fields}, å·²æœ‰ç´¢å¼•: {existing_indexed_fields}")
                    return True
            else:
                print(f"âŒ å­—æ®µ {fields_without_individual_indexes} ç¼ºå°‘ç´¢å¼•ï¼Œå·²æœ‰ç´¢å¼•: {existing_indexed_fields}")
                return False
        
        print(f"âš ï¸ æ— æ³•ç¡®å®šç´¢å¼•çŠ¶æ€ï¼Œå­—æ®µ: {all_fields} éœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥")
        # å¦‚æœæ— æ³•è·å–ä»»ä½•ç´¢å¼•ä¿¡æ¯ï¼Œä¿å®ˆåœ°è®¤ä¸ºå¯èƒ½ç¼ºå°‘ç´¢å¼•
        return False
    
    def _get_table_indexed_fields(self, table_name: str, database: str = '', query: Optional[dict] = None, hostname: str = None) -> set:
        """
        è·å–è¡¨çš„å·²æœ‰ç´¢å¼•å­—æ®µé›†åˆ
        
        Args:
            table_name: è¡¨åï¼ˆå¯èƒ½æ˜¯åˆ«åï¼Œéœ€è¦æ˜ å°„åˆ°å®é™…è¡¨åï¼‰
            database: æ•°æ®åº“å
            query: æŸ¥è¯¢å¯¹è±¡ï¼Œå¯èƒ½åŒ…å«è¡¨ç»“æ„ä¿¡æ¯
            hostname: ä¸»æœºå
            
        Returns:
            å·²æœ‰ç´¢å¼•çš„å­—æ®µé›†åˆï¼ˆå°å†™ï¼‰
        """
        existing_indexed_fields = set()
        
        if not table_name:
            return existing_indexed_fields
        
        # ä»queryå¯¹è±¡ä¸­è·å–hostname_maxç”¨äºè¿æ¥çœŸå®ä¸šåŠ¡æ•°æ®åº“
        hostname_max = hostname
        if not hostname_max and query and isinstance(query, dict):
            slow_info = query.get('slow_query_info', {})
            hostname_max = slow_info.get('hostname_max') or slow_info.get('ip') or query.get('hostname_max') or query.get('ip')
        
        # å°è¯•ä»queryå¯¹è±¡ä¸­è·å–è¡¨ç»“æ„ä¿¡æ¯ï¼ˆå¯èƒ½åŒ…å«å¤šä¸ªè¡¨çš„ä¿¡æ¯ï¼‰
        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æœ‰è¡¨ç»“æ„ä¿¡æ¯ï¼Œå¯èƒ½åŒ…å«å¤šä¸ªè¡¨
        table_structure = None
        if query and isinstance(query, dict):
            # å°è¯•ç›´æ¥è·å–è¡¨ç»“æ„
            if 'table_structure' in query:
                table_structure = query.get('table_structure', {})
            # ä¹Ÿå¯èƒ½åœ¨slow_query_infoä¸­
            elif 'slow_query_info' in query:
                slow_info = query.get('slow_query_info', {})
                if 'table_structure' in slow_info:
                    table_structure = slow_info.get('table_structure', {})
        
        # å¦‚æœtable_structureæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æ
        if table_structure and isinstance(table_structure, str):
            try:
                import json
                table_structure = json.loads(table_structure)
            except (json.JSONDecodeError, ValueError):
                try:
                    import ast
                    table_structure = ast.literal_eval(table_structure)
                except (ValueError, SyntaxError):
                    table_structure = {}
        
        # 1. ä¼˜å…ˆä»æ•°æ®åº“è·å–å®é™…ç´¢å¼•ä¿¡æ¯
        # ç¡®å®šæ­£ç¡®çš„æ•°æ®åº“ï¼šå¦‚æœdatabaseä¸ºç©ºï¼Œæˆ–è¡¨ä¸åœ¨è¯¥æ•°æ®åº“ä¸­ï¼Œåˆ™æŸ¥æ‰¾æ­£ç¡®çš„æ•°æ®åº“
        actual_db = database
        need_find_database = False
        
        # å¦‚æœdatabaseä¸ºç©ºï¼Œéœ€è¦æŸ¥æ‰¾
        if not actual_db:
            need_find_database = True
        # å¦‚æœdatabaseä¸ä¸ºç©ºï¼Œå…ˆéªŒè¯è¡¨æ˜¯å¦åœ¨è¯¥æ•°æ®åº“ä¸­
        elif actual_db and hostname_max and table_name:
            if not self.db_helper.check_table_exists(actual_db, table_name, hostname_max):
                print(f"âš ï¸ è¡¨ {table_name} åœ¨æ•°æ®åº“ {actual_db} ä¸­ä¸å­˜åœ¨ï¼Œå°†æŸ¥æ‰¾æ­£ç¡®çš„æ•°æ®åº“")
                need_find_database = True
        
        # å¦‚æœéœ€è¦æŸ¥æ‰¾æ•°æ®åº“ï¼Œé€šè¿‡hostname_maxæŸ¥æ‰¾è¡¨æ‰€åœ¨çš„æ•°æ®åº“
        if need_find_database and hostname_max and table_name:
            found_database = self.db_helper.find_correct_database_for_table(table_name, hostname_max)
            if found_database:
                actual_db = found_database
                print(f"ğŸ” é€šè¿‡hostname_maxæ‰¾åˆ°è¡¨ {table_name} æ‰€åœ¨çš„æ•°æ®åº“: {actual_db}")
            else:
                print(f"âŒ æ— æ³•æ‰¾åˆ°è¡¨ {table_name} æ‰€åœ¨çš„æ•°æ®åº“")
        
        # ä½¿ç”¨æ­£ç¡®çš„æ•°æ®åº“æŸ¥è¯¢ç´¢å¼•
        if actual_db and table_name:
            query_result = self.db_helper.execute_safe_query(
                f"SHOW INDEX FROM `{table_name}`",
                hostname=hostname_max,
                database=actual_db
            )
            if query_result['status'] == 'success' and query_result['data']:
                for row in query_result['data']:
                    if len(row) >= 5:
                        column_name = row[4]
                        if column_name:
                            existing_indexed_fields.add(column_name.lower())
                if existing_indexed_fields:
                    print(f"âœ… ä»æ•°æ®åº“ {actual_db} ä¸­è·å–åˆ°è¡¨ {table_name} çš„ç´¢å¼•å­—æ®µ: {existing_indexed_fields}")
                    return existing_indexed_fields
            else:
                # å¦‚æœæŸ¥è¯¢å¤±è´¥ï¼ˆå¦‚é”™è¯¯1146ï¼‰ï¼Œå°è¯•é‡æ–°æŸ¥æ‰¾æ•°æ®åº“
                error_msg = query_result.get('message', 'æœªçŸ¥é”™è¯¯')
                if '1146' in str(error_msg) or 'Table' in str(error_msg) and "doesn't exist" in str(error_msg):
                    print(f"âš ï¸ ä»æ•°æ®åº“ {actual_db} æŸ¥è¯¢è¡¨ {table_name} çš„ç´¢å¼•å¤±è´¥ï¼ˆè¡¨ä¸å­˜åœ¨ï¼‰ï¼Œé‡æ–°æŸ¥æ‰¾æ­£ç¡®çš„æ•°æ®åº“")
                    if hostname_max:
                        found_database = self.db_helper.find_correct_database_for_table(table_name, hostname_max)
                        if found_database and found_database != actual_db:
                            actual_db = found_database
                            print(f"ğŸ” é‡æ–°æ‰¾åˆ°è¡¨ {table_name} æ‰€åœ¨çš„æ•°æ®åº“: {actual_db}")
                            # ä½¿ç”¨æ–°æ‰¾åˆ°çš„æ•°æ®åº“é‡æ–°æŸ¥è¯¢
                            query_result = self.db_helper.execute_safe_query(
                                f"SHOW INDEX FROM `{table_name}`",
                                hostname=hostname_max,
                                database=actual_db
                            )
                            if query_result['status'] == 'success' and query_result['data']:
                                for row in query_result['data']:
                                    if len(row) >= 5:
                                        column_name = row[4]
                                        if column_name:
                                            existing_indexed_fields.add(column_name.lower())
                                if existing_indexed_fields:
                                    print(f"âœ… ä»æ•°æ®åº“ {actual_db} ä¸­è·å–åˆ°è¡¨ {table_name} çš„ç´¢å¼•å­—æ®µ: {existing_indexed_fields}")
                                    return existing_indexed_fields
                else:
                    print(f"âš ï¸ ä»æ•°æ®åº“ {actual_db} æŸ¥è¯¢è¡¨ {table_name} çš„ç´¢å¼•å¤±è´¥: {error_msg}")
        
        # 2. å¦‚æœæ•°æ®åº“æŸ¥è¯¢å¤±è´¥ï¼Œä»queryå¯¹è±¡ä¸­è·å–è¡¨ç»“æ„ä¿¡æ¯ä½œä¸ºå‚è€ƒ
        # éœ€è¦å¤„ç†è¡¨åå¯èƒ½æ˜¯åˆ«åçš„æƒ…å†µï¼Œå°è¯•åŒ¹é…å®é™…è¡¨å
        if table_structure and isinstance(table_structure, dict):
            # å¦‚æœtable_structureæ˜¯å•ä¸ªè¡¨çš„ç»“æ„
            if 'indexes' in table_structure:
                indexes = table_structure['indexes']
                self._extract_indexes_from_structure(indexes, existing_indexed_fields)
            # å¦‚æœtable_structureåŒ…å«å¤šä¸ªè¡¨çš„ç»“æ„ï¼ˆå­—å…¸æ ¼å¼ï¼š{table_name: structure}ï¼‰
            elif isinstance(table_structure, dict):
                # å°è¯•ç›´æ¥åŒ¹é…è¡¨å
                if table_name in table_structure:
                    table_info = table_structure[table_name]
                    if isinstance(table_info, dict) and 'indexes' in table_info:
                        indexes = table_info['indexes']
                        self._extract_indexes_from_structure(indexes, existing_indexed_fields)
                # å°è¯•å°å†™åŒ¹é…
                elif table_name.lower() in {k.lower(): v for k, v in table_structure.items()}:
                    for key, value in table_structure.items():
                        if key.lower() == table_name.lower() and isinstance(value, dict) and 'indexes' in value:
                            indexes = value['indexes']
                            self._extract_indexes_from_structure(indexes, existing_indexed_fields)
                            break
                # å¦‚æœéƒ½ä¸åŒ¹é…ï¼Œå°è¯•éå†æ‰€æœ‰è¡¨ç»“æ„ï¼ˆå¯èƒ½æ˜¯åˆ«åæ˜ å°„é—®é¢˜ï¼‰
                else:
                    for key, value in table_structure.items():
                        if isinstance(value, dict) and 'indexes' in value:
                            indexes = value['indexes']
                            self._extract_indexes_from_structure(indexes, existing_indexed_fields)
        
        return existing_indexed_fields
    
    def _extract_indexes_from_structure(self, indexes, existing_indexed_fields: set):
        """ä»ç´¢å¼•ç»“æ„ä¸­æå–ç´¢å¼•å­—æ®µ"""
        if isinstance(indexes, dict):
            for index_info in indexes.values():
                if isinstance(index_info, dict) and 'columns' in index_info:
                    for col in index_info['columns']:
                        if isinstance(col, str):
                            existing_indexed_fields.add(col.lower())
                        elif isinstance(col, dict) and 'column' in col:
                            existing_indexed_fields.add(col['column'].lower())
        elif isinstance(indexes, list):
            for index_info in indexes:
                if isinstance(index_info, dict):
                    if 'columns' in index_info:
                        for col in index_info['columns']:
                            if isinstance(col, str):
                                existing_indexed_fields.add(col.lower())
                            elif isinstance(col, dict) and 'column' in col:
                                existing_indexed_fields.add(col['column'].lower())
                    elif 'Column_name' in index_info:
                        existing_indexed_fields.add(index_info['Column_name'].lower())
    
    def _check_composite_index_exists(self, existing_indexed_fields: set, composite_fields: list) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦å·²æœ‰å¤åˆç´¢å¼•è¦†ç›–æŒ‡å®šçš„å­—æ®µç»„åˆ
        
        Args:
            existing_indexed_fields: å·²æœ‰ç´¢å¼•çš„å­—æ®µé›†åˆï¼ˆå°å†™ï¼‰
            composite_fields: éœ€è¦æ£€æŸ¥çš„å¤åˆç´¢å¼•å­—æ®µåˆ—è¡¨
            
        Returns:
            å¦‚æœå·²æœ‰å¤åˆç´¢å¼•è¦†ç›–è¿™äº›å­—æ®µï¼Œè¿”å›Trueï¼Œå¦åˆ™è¿”å›False
        """
        if not composite_fields:
            return False
            
        # æ£€æŸ¥å¤åˆç´¢å¼•çš„æœ€å·¦å‰ç¼€åŸåˆ™
        # å¦‚æœæ‰€æœ‰å­—æ®µéƒ½å·²æœ‰å•ç‹¬çš„ç´¢å¼•ï¼Œè®¤ä¸ºå¯ä»¥ç»„æˆå¤åˆç´¢å¼•
        for field in composite_fields:
            if field.lower() not in existing_indexed_fields:
                return False
        
        return True
    
    def _mask_table_structure(self, table_structure) -> str:
        """è„±æ•è¡¨ç»“æ„ä¿¡æ¯ï¼ˆåŒ…è£…æ–¹æ³•ï¼‰"""
        return DataMasking.mask_table_structure(table_structure)
    
    def _merge_analysis_results_to_compare_data(self, analysis_results: List[Dict]):
        """å°†DeepSeekåˆ†æç»“æœåˆå¹¶åˆ°compare_dataç»“æ„ä¸­ï¼ˆåŒ…è£…æ–¹æ³•ï¼‰"""
        DataProcessor.merge_analysis_results_to_compare_data(
            self.compare_data, 
            analysis_results, 
            DataProcessor.format_deepseek_suggestions
        )
    
    def _create_compare_data_with_analysis(self, analysis_results: List[Dict]) -> Dict:
        """åˆ›å»ºåŒ…å«DeepSeekåˆ†æç»“æœçš„compare_dataç»“æ„ï¼ˆåŒ…è£…æ–¹æ³•ï¼‰"""
        return DataProcessor.create_compare_data_with_analysis(
            analysis_results, 
            DataProcessor.format_deepseek_suggestions
        )
    
    def _format_deepseek_suggestions(self, deepseek_optimization, sql_content: str = '') -> str:
        """æ™ºèƒ½æ ¼å¼åŒ–DeepSeekä¼˜åŒ–å»ºè®®ï¼ˆåŒ…è£…æ–¹æ³•ï¼Œä¿ç•™å¤æ‚é€»è¾‘ï¼‰"""
        # ä½¿ç”¨DataProcessorçš„æ–¹æ³•ï¼Œä½†ä¿ç•™ä¸»æ–‡ä»¶ä¸­çš„å¤æ‚é€»è¾‘
        return DataProcessor.format_deepseek_suggestions(deepseek_optimization, sql_content)
    
    def _analyze_sql_for_optimization(self, sql_content: str, database: str = '', table: str = '', query: Optional[dict] = None, hostname: str = None) -> str:
        """
        æ™ºèƒ½åˆ†æSQLè¯­å¥ï¼Œç”Ÿæˆå…·ä½“çš„ä¼˜åŒ–å»ºè®®å’Œå¯æ‰§è¡Œè¯­å¥
        é‡ç‚¹å¤„ç†JOINæŸ¥è¯¢ï¼Œä¸ºå¤šè¡¨ç”Ÿæˆç´¢å¼•å»ºè®®
        """
        if not sql_content:
            return ""
        
        sql_lower = sql_content.lower()
        
        # æå–è¡¨åˆ«åæ˜ å°„
        table_alias_map = SQLAnalyzer.extract_table_aliases(sql_content)
        
        # æå–ä¸»è¡¨å
        primary_table = table or self._extract_table_name(sql_content) or 'your_table_name'
        primary_table_lower = primary_table.lower()
        
        # æå–å­—æ®µä¿¡æ¯
        where_fields = self._extract_where_fields(sql_content)
        join_fields = self._extract_join_fields(sql_content)
        
        # å¦‚æœæ²¡æœ‰WHEREå’ŒJOINå­—æ®µï¼Œè¿”å›ç¼ºå°‘è¿‡æ»¤æ¡ä»¶çš„è¯Šæ–­
        if not where_fields and not join_fields:
            return "\n".join([
                "1. æ™ºèƒ½è¯Šæ–­: æŸ¥è¯¢ç¼ºå°‘æœ‰æ•ˆçš„è¿‡æ»¤æ¡ä»¶ï¼Œå­˜åœ¨å…¨è¡¨æ‰«æé£é™©",
                "â€¢ å»ºè®®æ·»åŠ åŒ…å«ç´¢å¼•çš„è¿‡æ»¤æ¡ä»¶",
                "3. é¢„æœŸæ•ˆæœ: é¢„è®¡å¹³å‡æŸ¥è¯¢æ—¶é—´ä»60msé™ä½åˆ°3msï¼Œæ€§èƒ½æå‡çº¦20å€"
            ])
        
        # ä»queryå¯¹è±¡ä¸­è·å–æ•°æ®åº“åï¼ˆå¦‚æœdatabaseå‚æ•°ä¸ºç©ºï¼‰
        actual_database = database
        if not actual_database and query and isinstance(query, dict):
            actual_database = query.get('database') or query.get('db') or ''
            # ä¹Ÿå¯ä»¥ä»slow_query_infoä¸­è·å–
            if not actual_database:
                slow_info = query.get('slow_query_info', {})
                actual_database = slow_info.get('database') or slow_info.get('db') or ''
        
        # åˆ†æJOINæ¡ä»¶ï¼Œæå–æ¯ä¸ªè¡¨æ¶‰åŠçš„å­—æ®µ
        table_field_usage = defaultdict(lambda: {'where': [], 'join': []})
        
        # è§£æWHEREå­—æ®µï¼Œè¯†åˆ«è¡¨åˆ«å
        sql_upper = sql_content.upper()
        if 'WHERE' in sql_upper:
            where_clause = sql_content[sql_upper.find('WHERE') + 5:]
            # æå–å¸¦è¡¨åˆ«åçš„å­—æ®µ
            alias_field_pattern = r'([a-zA-Z_]\w*)\s*\.\s*([a-zA-Z_]\w*)'
            alias_matches = re.findall(alias_field_pattern, where_clause, re.IGNORECASE)
            for alias_name, column_name in alias_matches:
                alias_clean = alias_name.strip('`')
                column_clean = column_name.strip('`')
                # ä¼˜å…ˆä»åˆ«åæ˜ å°„ä¸­è·å–å®é™…è¡¨åï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨åˆ«åæœ¬èº«ï¼ˆå¯èƒ½æ˜¯è¡¨åï¼‰
                actual_table = table_alias_map.get(alias_clean, alias_clean)
                if actual_table:
                    table_field_usage[actual_table]['where'].append(column_clean)
            # æ— åˆ«åçš„å­—æ®µå½’å±ä¸»è¡¨
            for field in where_fields:
                if '.' not in field:
                    table_field_usage[primary_table]['where'].append(field)
        
        # è§£æJOINå­—æ®µï¼Œè¯†åˆ«æ¯ä¸ªè¡¨
        # æ”¯æŒ WHERE a.id=b.id å’Œ ON a.id=b.id ä¸¤ç§æ ¼å¼
        join_condition_pattern = r'([a-zA-Z_]\w*\.[a-zA-Z_]\w*)\s*=\s*([a-zA-Z_]\w*\.[a-zA-Z_]\w*)'
        join_matches = re.findall(join_condition_pattern, sql_content, re.IGNORECASE)
        for left_operand, right_operand in join_matches:
            for operand in (left_operand, right_operand):
                if '.' in operand:
                    alias_part, column_part = operand.split('.', 1)
                    alias = alias_part.strip('`')
                    column = column_part.strip('`')
                    # ä¼˜å…ˆä»åˆ«åæ˜ å°„ä¸­è·å–å®é™…è¡¨åï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨åˆ«åæœ¬èº«ï¼ˆå¯èƒ½æ˜¯è¡¨åï¼‰
                    actual_table = table_alias_map.get(alias, alias)
                    if actual_table and column:
                        # é¿å…é‡å¤æ·»åŠ 
                        if column not in table_field_usage[actual_table]['join']:
                            table_field_usage[actual_table]['join'].append(column)
        
        # æ„å»ºä¼˜åŒ–å»ºè®®
        optimization_parts = []
        solutions = []
        executable_actions = []
        
        # 1. æ™ºèƒ½è¯Šæ–­
        core_issues = []
        # æ”¶é›†æ‰€æœ‰è¡¨çš„å­—æ®µéœ€æ±‚ï¼Œåˆå¹¶WHEREå’ŒJOINå­—æ®µï¼Œé¿å…é‡å¤
        # åŒæ—¶æ£€æŸ¥æ¯ä¸ªè¡¨çš„å­—æ®µæ˜¯å¦å·²æœ‰ç´¢å¼•ï¼Œåªæç¤ºç¼ºå°‘ç´¢å¼•çš„å­—æ®µ
        for table_key, usage in table_field_usage.items():
            all_fields = []
            field_types = []
            
            # æ”¶é›†WHEREå­—æ®µ
            if usage['where']:
                where_fields_list = sorted(set(usage['where']))
                all_fields.extend(where_fields_list)
                field_types.append('WHERE')
            
            # æ”¶é›†JOINå­—æ®µï¼ˆå»é‡ï¼‰
            if usage['join']:
                join_fields_list = sorted(set(usage['join']))
                for field in join_fields_list:
                    if field not in all_fields:
                        all_fields.append(field)
                if 'JOIN' not in field_types:
                    field_types.append('JOIN')
            
            # æ£€æŸ¥å“ªäº›å­—æ®µç¼ºå°‘ç´¢å¼•
            if all_fields:
                # è·å–è¯¥è¡¨çš„å·²æœ‰ç´¢å¼•å­—æ®µï¼ˆä½¿ç”¨å®é™…çš„æ•°æ®åº“åï¼‰
                existing_indexed_fields = self._get_table_indexed_fields(table_key, actual_database, query, hostname)
                
                # è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å°ç´¢å¼•æ£€æŸ¥ç»“æœ
                if existing_indexed_fields:
                    print(f"ğŸ” è¡¨ {table_key} çš„å·²æœ‰ç´¢å¼•å­—æ®µ: {existing_indexed_fields}")
                else:
                    print(f"âš ï¸ è¡¨ {table_key} æœªæ‰¾åˆ°ç´¢å¼•ä¿¡æ¯ï¼ˆæ•°æ®åº“: {actual_database}ï¼‰")
                
                # è¿‡æ»¤å‡ºç¼ºå°‘ç´¢å¼•çš„å­—æ®µ
                missing_index_fields = []
                for field in all_fields:
                    field_lower = field.lower()
                    if field_lower not in existing_indexed_fields:
                        missing_index_fields.append(field)
                    else:
                        print(f"âœ… è¡¨ {table_key} çš„å­—æ®µ {field} å·²æœ‰ç´¢å¼•ï¼Œè·³è¿‡")
                
                # åªå¯¹ç¼ºå°‘ç´¢å¼•çš„å­—æ®µç”Ÿæˆè¯Šæ–­æç¤º
                if missing_index_fields:
                    if len(field_types) == 2:
                        # åŒæ—¶æœ‰WHEREå’ŒJOINå­—æ®µï¼Œåˆå¹¶æè¿°
                        core_issues.append(f"è¡¨ {table_key} çš„å­—æ®µ {', '.join(missing_index_fields)} éœ€è¦ç´¢å¼•ï¼ˆç”¨äºWHEREå’ŒJOINæ¡ä»¶ï¼‰")
                    elif 'WHERE' in field_types:
                        core_issues.append(f"è¡¨ {table_key} çš„ WHERE å­—æ®µ {', '.join(missing_index_fields)} éœ€è¦ç´¢å¼•")
                    elif 'JOIN' in field_types:
                        core_issues.append(f"è¡¨ {table_key} çš„ JOIN å­—æ®µ {', '.join(missing_index_fields)} éœ€è¦ç´¢å¼•")
        
        # å¦‚æœæ²¡æœ‰æ”¶é›†åˆ°ä»»ä½•ä¿¡æ¯ï¼Œä½¿ç”¨é€šç”¨æè¿°
        if not core_issues:
            if where_fields:
                # å¦‚æœæ²¡æœ‰è¡¨ä¿¡æ¯ï¼Œè‡³å°‘æ˜¾ç¤ºå­—æ®µ
                core_issues.append(f"WHEREæ¡ä»¶å­—æ®µ {', '.join(where_fields[:3])} éœ€è¦ç´¢å¼•æ”¯æŒ")
            else:
                core_issues.append("SQLè¯­å¥å¯èƒ½å­˜åœ¨æ€§èƒ½ä¼˜åŒ–ç©ºé—´")
        
        optimization_parts.append(f"1. æ™ºèƒ½è¯Šæ–­ï¼š{'ï¼›'.join(core_issues)}")
        
        # 2. ä¸ºä¸»è¡¨ç”Ÿæˆå¤åˆç´¢å¼•å»ºè®®ï¼ˆWHERE+JOINï¼‰
        primary_usage = table_field_usage.get(primary_table, {'where': [], 'join': []})
        primary_where = primary_usage.get('where', [])
        primary_join = primary_usage.get('join', [])
        
        if primary_where or primary_join:
            # è·å–ä¸»è¡¨çš„å·²æœ‰ç´¢å¼•å­—æ®µï¼ˆä½¿ç”¨å®é™…çš„æ•°æ®åº“åï¼‰
            primary_existing_indexes = self._get_table_indexed_fields(primary_table, actual_database, query, hostname)
            
            combined_fields = []
            # å…ˆæ·»åŠ WHEREå­—æ®µï¼ˆè¿‡æ»¤æ¡ä»¶ä¼˜å…ˆï¼‰ï¼Œè¿‡æ»¤æ‰å·²æœ‰ç´¢å¼•çš„å­—æ®µ
            for col in primary_where:
                if col and col.lower() not in primary_existing_indexes and col not in combined_fields:
                    combined_fields.append(col)
            # å†æ·»åŠ JOINå­—æ®µï¼Œè¿‡æ»¤æ‰å·²æœ‰ç´¢å¼•çš„å­—æ®µ
            for col in primary_join:
                if col and col.lower() not in primary_existing_indexes and col not in combined_fields:
                    combined_fields.append(col)
            
            if combined_fields:
                fields_subset = combined_fields[:5]
                index_name = f"idx_{'_'.join(fields_subset)}_composite"
                fields_str = ', '.join(fields_subset)
                solutions.append(f"ğŸ”¥ ä¸ºè¡¨ {primary_table} åˆ›å»ºå¤åˆç´¢å¼•ï¼ˆWHERE+JOINï¼‰ï¼š{fields_str}")
                executable_actions.append(f"-- ğŸ”¥ã€ä¸»è¡¨å¤åˆç´¢å¼•ã€‘è¡¨ {primary_table}ï¼ˆWHERE+JOINå­—æ®µï¼‰")
                executable_actions.append(f"CREATE INDEX {index_name} ON {primary_table}({fields_str});")
        
        # 3. ä¸ºéä¸»è¡¨ç”ŸæˆJOINå­—æ®µç´¢å¼•å»ºè®®
        for table_key, usage in table_field_usage.items():
            if table_key.lower() == primary_table_lower:
                continue
            
            # è·å–è¯¥è¡¨çš„å·²æœ‰ç´¢å¼•å­—æ®µï¼ˆä½¿ç”¨å®é™…çš„æ•°æ®åº“åï¼‰
            table_existing_indexes = self._get_table_indexed_fields(table_key, actual_database, query, hostname)
            
            combined_order = []
            # è¿‡æ»¤æ‰å·²æœ‰ç´¢å¼•çš„å­—æ®µ
            for col in usage['where']:
                if col and col.lower() not in table_existing_indexes and col not in combined_order:
                    combined_order.append(col)
            for col in usage['join']:
                if col and col.lower() not in table_existing_indexes and col not in combined_order:
                    combined_order.append(col)
            
            if not combined_order:
                continue
            
            if len(combined_order) >= 2:
                fields_subset = combined_order[:5]
                index_name = f"idx_{table_key.replace('.', '_')}_{'_'.join(fields_subset)}_join"
                fields_str = ', '.join(fields_subset)
                solutions.append(f"ğŸ”¥ ä¸ºè¡¨ {table_key} åˆ›å»ºå¤åˆç´¢å¼•è¦†ç›–JOINå­—æ®µï¼š{fields_str}")
                executable_actions.append(f"-- ğŸ”¥ã€è·¨è¡¨JOINå¤åˆç´¢å¼•ã€‘è¡¨ {table_key}")
                executable_actions.append(f"CREATE INDEX {index_name} ON {table_key}({fields_str});")
            else:
                field = combined_order[0]
                index_name = f"idx_{table_key.replace('.', '_')}_{field}_join"
                solutions.append(f"ä¸ºè¡¨ {table_key} çš„ JOIN å­—æ®µ {field} åˆ›å»ºå•åˆ—ç´¢å¼•ä¼˜åŒ–è¿æ¥æ€§èƒ½")
                executable_actions.append(f"-- âœ… ä¸ºè¡¨ {table_key} çš„ JOINå­—æ®µ {field} åˆ›å»ºå•åˆ—ç´¢å¼•")
                executable_actions.append(f"CREATE INDEX {index_name} ON {table_key}({field});")
        
        # 4. æ„å»ºå®Œæ•´çš„ä¼˜åŒ–å»ºè®®å­—ç¬¦ä¸²
        # ä¸æ·»åŠ  "2. æ™ºèƒ½ä¼˜åŒ–å»ºè®®ï¼š" æˆ– "æ™ºèƒ½ä¼˜åŒ–å»ºè®®ï¼š" æ ‡è®°ï¼Œç›´æ¥æ·»åŠ  SQL ä»£ç å—ï¼Œè®© report_generator_core.py é€šè¿‡æ£€æµ‹ "```sql" æ¥è¯†åˆ«
        if executable_actions:
            optimization_parts.append("```sql")
            optimization_parts.extend(executable_actions)
            optimization_parts.append("```")
        
        # 5. é¢„æœŸæ•ˆæœ
        if solutions:
            optimization_parts.append("3. é¢„æœŸæ•ˆæœ: é¢„è®¡å¹³å‡æŸ¥è¯¢æ—¶é—´å¯é™ä½50%ä»¥ä¸Šï¼ŒJOINæ€§èƒ½æ˜¾è‘—æå‡")
        
        return "\n".join(optimization_parts)
    
    def _convert_analysis_to_queries(self, analysis_results: List[Dict]) -> List[Dict]:
        """å°†åˆ†æç»“æœè½¬æ¢ä¸ºæŸ¥è¯¢åˆ—è¡¨æ ¼å¼ï¼ˆåŒ…è£…æ–¹æ³•ï¼‰"""
        return DataProcessor.convert_analysis_to_queries(
            analysis_results, 
            self._format_deepseek_suggestions
        )
    
    def create_report(self) -> str:
        """åˆ›å»ºWordæ ¼å¼çš„æ•°æ®åº“ä¼˜åŒ–åˆ†ææŠ¥å‘Šï¼ˆåŒ…è£…æ–¹æ³•ï¼Œè°ƒç”¨æ–°æ¨¡å—ï¼‰"""
        import os
        from docx import Document
        from datetime import datetime
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = "."
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"æ•°æ®åº“æ™ºèƒ½ä¼˜åŒ–åˆ†ææŠ¥å‘Š_{timestamp}.docx"
        filepath = os.path.join(output_dir, filename)
        
        # åˆ›å»ºWordæ–‡æ¡£
        doc = Document()
        
        # åˆ›å»ºæŠ¥å‘Šç”Ÿæˆæ ¸å¿ƒå®ä¾‹
        report_core = ReportGeneratorCore(
            document=doc,
            analysis_data=self.analysis_data,
            compare_data=self.compare_data,
            db_helper=self.db_helper,
            sql_optimizer=self._analyze_sql_for_optimization
        )
        
        # è®¾ç½®é¡µé¢å¸ƒå±€å’Œæ ·å¼
        report_core.setup_page_layout()
        report_core.setup_document_styles()
        
        # ç”ŸæˆæŠ¥å‘Šå„éƒ¨åˆ†
        report_core.generate_report_header()
        report_core.generate_report_summary()
        report_core.add_compare_analysis()
        report_core.generate_top_sql_statements()
        report_core.generate_sql_details()
        
        # ç”Ÿæˆæ€»ç»“å’Œå»ºè®®ï¼ˆä½¿ç”¨ SummaryGeneratorï¼‰
        summary_gen = SummaryGenerator(
            document=doc,
            analysis_data=self.analysis_data,
            compare_data=self.compare_data
        )
        summary_gen.generate_summary_and_recommendations()
        
        # ç”ŸæˆæŠ¥å‘Šé¡µè„š
        report_core.generate_report_footer()
        
        # ä¿å­˜æ–‡æ¡£
        doc.save(filepath)
        
        print(f"WordæŠ¥å‘Šå·²ç”Ÿæˆ: {filepath}")
        return filepath
     
    def _generate_optimization_suggestions(self):
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        self.document.add_heading('å…­ã€ä¼˜åŒ–å»ºè®®', level=1)
        
        # ç¡®ä¿analysis_dataä¸ä¸ºNone
        if self.analysis_data is None:
            self.analysis_data = []
        
        for i, query in enumerate(self.analysis_data, 1):
            # åˆ›å»ºæ™ºèƒ½ä¼˜åŒ–å»ºè®®æ ‡é¢˜
            self.document.add_heading(f'æ™ºèƒ½ä¼˜åŒ–å»ºè®® #{i}', level=2)
            
            # æå–ä¼˜åŒ–å»ºè®®å„éƒ¨åˆ† - ä¼˜å…ˆä½¿ç”¨deepseek_optimizationï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨optimization_suggestions
            suggestions = query.get('deepseek_optimization', '') or query.get('optimization_suggestions', '')
            
            # å¦‚æœdeepseek_optimizationæ˜¯åˆ—è¡¨ï¼Œè½¬æ¢ä¸ºç»“æ„åŒ–å­—ç¬¦ä¸²æ ¼å¼
            if isinstance(suggestions, list):
                # å°†åˆ—è¡¨è½¬æ¢ä¸ºç»“æ„åŒ–å»ºè®®æ ¼å¼
                structured_suggestions = []
                for item in suggestions:
                    if 'å·²å­˜åœ¨ç´¢å¼•' in item or 'æœ€ä¼˜çŠ¶æ€' in item:
                        structured_suggestions.append(f"1. æ™ºèƒ½è¯Šæ–­: {item}")
                    elif 'è¡¨ä¸å­˜åœ¨' in item:
                        structured_suggestions.append(f"1. æ™ºèƒ½è¯Šæ–­: {item}")
                    elif 'æœªæ‰¾åˆ°åˆé€‚çš„ç´¢å¼•' in item or 'å»ºè®®åˆ†ææŸ¥è¯¢æ¨¡å¼' in item:
                        # å¤„ç†é€šç”¨çš„ç´¢å¼•å»ºè®®
                        structured_suggestions.append(f"1. æ™ºèƒ½è¯Šæ–­: {item}")
                        structured_suggestions.append("å»ºè®®åˆ†æè¯¥SQLçš„æŸ¥è¯¢æ¨¡å¼ï¼Œè€ƒè™‘æ·»åŠ åˆé€‚çš„ç´¢å¼•")
                        # structured_suggestions.append("3. é¢„æœŸæ•ˆæœ: é€šè¿‡æ·»åŠ åˆé€‚ç´¢å¼•ï¼ŒæŸ¥è¯¢æ€§èƒ½é¢„è®¡å¯æå‡60-90%")
                        
                        # æ·»åŠ å…·ä½“çš„ç´¢å¼•å»ºè®®
                        structured_suggestions.append("4. å…·ä½“ç´¢å¼•å»ºè®®:")
                        
                        # ä»SQLè¯­å¥ä¸­æå–è¡¨åå’Œå­—æ®µä¿¡æ¯
                        sql_content = query.get('sql', query.get('sql_content', ''))
                        if sql_content:
                            # åˆ†æWHEREæ¡ä»¶ä¸­çš„å­—æ®µ
                            where_fields = self._extract_where_fields(sql_content)
                            if where_fields:
                                for field in where_fields:
                                    index_name = f"idx_{field}"
                                    structured_suggestions.append(f"   â€¢ å»ºè®®åˆ›å»ºç´¢å¼•: `{index_name}({field})`")
                                    structured_suggestions.append(f"     SQL: CREATE INDEX {index_name} ON table_name({field});")
                            
                            # åˆ†æJOINæ¡ä»¶ä¸­çš„å­—æ®µ
                            join_fields = self._extract_join_fields(sql_content)
                            if join_fields:
                                for field in join_fields:
                                    index_name = f"idx_{field}_join"
                                    structured_suggestions.append(f"   â€¢ JOINå­—æ®µç´¢å¼•: `{index_name}({field})`")
                                    structured_suggestions.append(f"     SQL: CREATE INDEX {index_name} ON table_name({field});")
                            
                            # åˆ†æORDER BYå­—æ®µ
                            order_fields = self._extract_order_fields(sql_content)
                            if order_fields:
                                for field in order_fields:
                                    index_name = f"idx_{field}_order"
                                    structured_suggestions.append(f"   â€¢ æ’åºå­—æ®µç´¢å¼•: `{index_name}({field})`")
                                    structured_suggestions.append(f"     SQL: CREATE INDEX {index_name} ON table_name({field});")
                            
                            # å¦‚æœæ²¡æœ‰æå–åˆ°å…·ä½“å­—æ®µï¼Œæä¾›é€šç”¨å»ºè®®
                            if not where_fields and not join_fields and not order_fields:
                                structured_suggestions.append("   â€¢ è¯·æ£€æŸ¥SQLè¯­å¥ä¸­çš„WHEREã€JOINå’ŒORDER BYå­å¥")
                                structured_suggestions.append("   â€¢ ä¸ºç»å¸¸ç”¨äºæŸ¥è¯¢æ¡ä»¶çš„å­—æ®µåˆ›å»ºå•åˆ—ç´¢å¼•")
                                structured_suggestions.append("   â€¢ è€ƒè™‘åˆ›å»ºå¤åˆç´¢å¼•ä»¥æ”¯æŒå¤šæ¡ä»¶æŸ¥è¯¢")
                                structured_suggestions.append("   â€¢ ç´¢å¼•ç¤ºä¾‹: CREATE INDEX idx_column ON table_name(column);")
                        
                        structured_suggestions.append("5. æ³¨æ„äº‹é¡¹:")
                        structured_suggestions.append("   â€¢ åœ¨åˆ›å»ºç´¢å¼•å‰ï¼Œè¯·è¯„ä¼°è¡¨çš„å†™æ“ä½œé¢‘ç‡")
                        structured_suggestions.append("   â€¢ é¿å…åœ¨é¢‘ç¹æ›´æ–°çš„å­—æ®µä¸Šåˆ›å»ºç´¢å¼•")
                        structured_suggestions.append("   â€¢ å»ºè®®å…ˆåœ¨æµ‹è¯•ç¯å¢ƒéªŒè¯ç´¢å¼•æ•ˆæœ")
                        structured_suggestions.append("   â€¢ ä½¿ç”¨EXPLAINå‘½ä»¤éªŒè¯ç´¢å¼•æ˜¯å¦è¢«ä½¿ç”¨")
                    else:
                        # å¯¹äºå…¶ä»–ç±»å‹çš„å»ºè®®ï¼Œä¹Ÿè½¬æ¢ä¸ºç»“æ„åŒ–æ ¼å¼
                        structured_suggestions.append(f"1. æ™ºèƒ½è¯Šæ–­: {item}")
                        structured_suggestions.append("å»ºè®®è¿›ä¸€æ­¥åˆ†æè¯¥æŸ¥è¯¢çš„æ‰§è¡Œè®¡åˆ’")
                        structured_suggestions.append("3. é¢„æœŸæ•ˆæœ: é€šè¿‡ä¼˜åŒ–ï¼ŒæŸ¥è¯¢æ€§èƒ½æœ‰æœ›å¾—åˆ°æ˜¾è‘—æå‡")
                suggestions = '\n\n'.join(structured_suggestions)
            
            # æ£€æŸ¥ä¼˜åŒ–å»ºè®®æ˜¯å¦ä¸ºç©ºæˆ–æ— æ•ˆ
            if not suggestions or (isinstance(suggestions, str) and not suggestions.strip()) or suggestions == 'æš‚æ— ä¼˜åŒ–å»ºè®®':
                # ä½¿ç”¨æ™ºèƒ½åˆ†æç”Ÿæˆå…·ä½“çš„ä¼˜åŒ–å»ºè®®
                sql_content = query.get('sql', query.get('sql_content', ''))
                database = query.get('database', query.get('db_name', ''))
                table = query.get('table', '')
                
                # å¦‚æœæ²¡æœ‰è¡¨åï¼Œå°è¯•ä»SQLè¯­å¥ä¸­æå–
                if not table and sql_content:
                    table = self._extract_table_name(sql_content)
                
                # è·å–hostname_maxç”¨äºè¿æ¥çœŸå®çš„ä¸šåŠ¡æ•°æ®åº“
                slow_info = query.get('slow_query_info', {})
                hostname_max = slow_info.get('hostname_max') or slow_info.get('ip') or query.get('hostname_max') or query.get('ip')
                
                suggestions = self._analyze_sql_for_optimization(sql_content, database, table, query, hostname_max)
            
            # å¦‚æœä»ç„¶æ²¡æœ‰æœ‰æ•ˆå»ºè®®ï¼Œæ˜¾ç¤ºé€šç”¨å»ºè®®
            if not suggestions or (isinstance(suggestions, str) and not suggestions.strip()):
                # ä¼˜åŒ–å»ºè®®ä¸ºç©ºçš„æƒ…å†µ
                empty_box = self.document.add_paragraph()
                empty_run = empty_box.add_run("âš  è¯¥SQLæš‚æ— å…·ä½“çš„ä¼˜åŒ–å»ºè®®")
                empty_run.font.name = 'å¾®è½¯é›…é»‘'
                empty_run.font.size = Pt(11)
                empty_run.font.color.rgb = RGBColor(255, 140, 0)  # æ©™è‰²è­¦å‘Š
                empty_run.bold = True
                empty_box.paragraph_format.space_before = Pt(6)
                empty_box.paragraph_format.space_after = Pt(6)
                
                # æä¾›é€šç”¨å»ºè®®
                general_title = self.document.add_paragraph()
                general_run = general_title.add_run('é€šç”¨ä¼˜åŒ–å»ºè®®:')
                general_run.bold = True
                general_run.font.name = 'å¾®è½¯é›…é»‘'
                general_run.font.size = Pt(11)
                
                general_content = self.document.add_paragraph()
                general_content_run = general_content.add_run(
                    "è¯„ä¼°æ˜¯å¦å¯ä»¥ä¼˜åŒ–SQLè¯­å¥ç»“æ„\n"
                )
                general_content_run.font.name = 'å®‹ä½“'
                general_content_run.font.size = Pt(10.5)
                general_content.paragraph_format.left_indent = Pt(15)
                
                # æ·»åŠ ç©ºè¡Œå’Œåˆ†éš”çº¿ï¼Œç„¶åç»§ç»­ä¸‹ä¸€ä¸ªæŸ¥è¯¢
                self._add_separator_line()
                continue
            
            # æ·»åŠ èƒŒæ™¯è‰²çš„æç¤ºæ¡†ï¼ˆä»…åœ¨æœ‰ä¼˜åŒ–å»ºè®®æ—¶æ˜¾ç¤ºï¼‰
            highlight_box = self.document.add_paragraph()
            highlight_run = highlight_box.add_run("ä»¥ä¸‹æ˜¯é’ˆå¯¹è¯¥SQLçš„è¯¦ç»†ä¼˜åŒ–å»ºè®®")
            highlight_run.font.name = 'å¾®è½¯é›…é»‘'
            highlight_run.font.size = Pt(11)
            highlight_run.font.color.rgb = RGBColor(192, 0, 0)
            highlight_run.bold = True
            highlight_box.paragraph_format.space_before = Pt(6)
            highlight_box.paragraph_format.space_after = Pt(6)
            
            # åˆ†å‰²å»ºè®®å†…å®¹
            # ä½¿ç”¨æ›´æ™ºèƒ½çš„åˆ†å‰²æ–¹å¼ï¼Œç¡®ä¿é¢„æœŸæ•ˆæœéƒ¨åˆ†ä¸ä¼šè¢«é”™è¯¯åˆ†å‰²
            parts = []
            
            # å…ˆå°è¯•æŒ‰ç¼–å·åˆ†å‰²
            lines = suggestions.split('\n')
            current_part = []
            
            for line in lines:
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°çš„éƒ¨åˆ†å¼€å§‹ï¼ˆä»¥æ•°å­—ç¼–å·å¼€å¤´ï¼‰
                if re.match(r'^\d+\.', line.strip()) or re.match(r'^\*\*\d+\.', line.strip()):
                    # å¦‚æœå½“å‰éƒ¨åˆ†ä¸ä¸ºç©ºï¼Œä¿å­˜å®ƒ
                    if current_part:
                        parts.append('\n'.join(current_part))
                        current_part = []
                current_part.append(line)
            
            # æ·»åŠ æœ€åä¸€éƒ¨åˆ†
            if current_part:
                parts.append('\n'.join(current_part))
            
            # å¦‚æœæ²¡æœ‰æ­£ç¡®åˆ†å‰²ï¼Œä½¿ç”¨åŸå§‹æ–¹å¼
            if len(parts) <= 1:
                parts = suggestions.split('\n\n')
            
            for part in parts:
                if part.startswith('1. æ™ºèƒ½è¯Šæ–­') or part.startswith('**1. æ™ºèƒ½è¯Šæ–­**'):
                    # æ™ºèƒ½è¯Šæ–­éƒ¨åˆ†
                    issue_title = self.document.add_paragraph()
                    issue_title_run = issue_title.add_run('ğŸ¯ æ™ºèƒ½è¯Šæ–­:')
                    issue_title_run.bold = True
                    issue_title_run.font.name = 'å¾®è½¯é›…é»‘'
                    issue_title_run.font.size = Pt(11)
                    issue_title_run.font.color.rgb = RGBColor(192, 0, 0)  # çº¢è‰²çªå‡ºé—®é¢˜
                    
                    # å»é™¤æ ‡è®°å¹¶æ·»åŠ å†…å®¹
                    content = re.sub(r'1\.\s*æ™ºèƒ½è¯Šæ–­[:ï¼š]?\s*|\*\*1\.\s*æ™ºèƒ½è¯Šæ–­\*\*\s*', '', part)
                    issue_content = self.document.add_paragraph()
                    issue_content_run = issue_content.add_run(content)
                    issue_content_run.font.name = 'å®‹ä½“'
                    issue_content_run.font.size = Pt(10.5)
                    issue_content_run.font.color.rgb = RGBColor(192, 0, 0)
                    issue_content.paragraph_format.left_indent = Pt(15)
                
                elif part.startswith('2. æ™ºèƒ½ä¼˜åŒ–å»ºè®®') or part.startswith('**2. æ™ºèƒ½ä¼˜åŒ–å»ºè®®**'):
                    # æ™ºèƒ½ä¼˜åŒ–å»ºè®®éƒ¨åˆ† - åªæœ‰å½“å†…å®¹ä¸åŒ…å«"æœ€ä¼˜çŠ¶æ€"æ—¶æ‰æ·»åŠ 
                    # ç§»é™¤äº†é‡å¤çš„"æ™ºèƒ½ä¼˜åŒ–å»ºè®®:"æ ‡é¢˜ï¼Œé¿å…ä¸å†…å®¹é‡å¤
                    
                    # å¤„ç†SQLä»£ç å—
                    if '```sql' in part:
                        # ç§»é™¤```sqlå’Œ```æ ‡è®°ï¼Œåªä¿ç•™SQLä»£ç å†…å®¹
                        # å…ˆç§»é™¤å¼€å¤´çš„```sql
                        sql_content = re.sub(r'^```sql\s*\n?', '', part, flags=re.MULTILINE)
                        # ç§»é™¤ç»“å°¾çš„```
                        sql_content = re.sub(r'\n?```\s*$', '', sql_content, flags=re.MULTILINE)
                        # ç§»é™¤ä¸­é—´çš„```sqlå’Œ```æ ‡è®°
                        sql_content = re.sub(r'```sql\s*\n?', '', sql_content, flags=re.MULTILINE)
                        sql_content = re.sub(r'\n?```\s*', '', sql_content, flags=re.MULTILINE)
                        
                        # ç§»é™¤"2. æ™ºèƒ½ä¼˜åŒ–å»ºè®®"æ ‡è®°
                        sql_content = re.sub(r'2\.\s*æ™ºèƒ½ä¼˜åŒ–å»ºè®®[:ï¼š]?\s*|\*\*2\.\s*æ™ºèƒ½ä¼˜åŒ–å»ºè®®\*\*\s*', '', sql_content)
                        
                        # å¤„ç†SQLä»£ç 
                        if sql_content.strip():
                            sql_lines = sql_content.strip().split('\n')
                            for sql_line in sql_lines:
                                if sql_line.strip():
                                    sql_para = self.document.add_paragraph()
                                    sql_run = sql_para.add_run(sql_line)
                                    sql_run.font.name = 'Consolas'
                                    sql_run.font.size = Pt(9)
                                    
                                    if sql_line.strip().startswith('-- ğŸ”¥'):
                                        sql_run.font.color.rgb = RGBColor(255, 0, 0)
                                        sql_run.font.bold = True
                                    elif sql_line.strip().startswith('-- ğŸ”') or sql_line.strip().startswith('-- âœ…'):
                                        sql_run.font.color.rgb = RGBColor(0, 100, 200)
                                        sql_run.font.bold = True
                                    elif sql_line.strip().startswith('--'):
                                        sql_run.font.color.rgb = RGBColor(128, 128, 128)
                                    elif 'CREATE INDEX' in sql_line.upper() or 'ALTER TABLE' in sql_line.upper():
                                        sql_run.font.color.rgb = RGBColor(0, 128, 0)
                                        sql_run.font.bold = True
                                    else:
                                        sql_run.font.color.rgb = RGBColor(0, 0, 0)
                                    
                                    sql_para.paragraph_format.left_indent = Pt(20)
                                    sql_para.paragraph_format.space_before = Pt(0)
                                    sql_para.paragraph_format.space_after = Pt(0)
                    else:
                        # æ™®é€šæ–‡æœ¬æ™ºèƒ½ä¼˜åŒ–å»ºè®®
                        content = re.sub(r'2\.\s*æ™ºèƒ½ä¼˜åŒ–å»ºè®®[:ï¼š]?\s*|\*\*2\.\s*æ™ºèƒ½ä¼˜åŒ–å»ºè®®\*\*\s*', '', part)
                        solution_content = self.document.add_paragraph()
                        solution_content_run = solution_content.add_run(content)
                        solution_content_run.font.name = 'å®‹ä½“'
                        solution_content_run.font.size = Pt(10.5)
                        solution_content.paragraph_format.left_indent = Pt(15)
                
                elif part.startswith('3. é¢„æœŸæ•ˆæœ') or part.startswith('**3. é¢„æœŸæ•ˆæœ**'):
                    # é¢„æœŸæ•ˆæœéƒ¨åˆ†
                    effect_title = self.document.add_paragraph()
                    effect_title_run = effect_title.add_run('ğŸš€ é¢„æœŸæ•ˆæœ:')
                    effect_title_run.bold = True
                    effect_title_run.font.name = 'å¾®è½¯é›…é»‘'
                    effect_title_run.font.size = Pt(11)
                    effect_title_run.font.color.rgb = RGBColor(0, 0, 192)  # è“è‰²æ•ˆæœæ ‡é¢˜
                    effect_title_run.font.color.rgb = RGBColor(0, 0, 192)  # è“è‰²æ•ˆæœæ ‡é¢˜
                    
                    content = re.sub(r'3\.\s*é¢„æœŸæ•ˆæœ[:ï¼š]?\s*|\*\*3\.\s*é¢„æœŸæ•ˆæœ\*\*\s*', '', part)
                    effect_content = self.document.add_paragraph()
                    effect_content_run = effect_content.add_run(content)
                    effect_content_run.font.name = 'å®‹ä½“'
                    effect_content_run.font.size = Pt(10.5)
                    effect_content_run.font.color.rgb = RGBColor(0, 0, 192)  # è“è‰²æ•ˆæœæ–‡æœ¬
                    effect_content.paragraph_format.left_indent = Pt(15)
                
                # æ·»åŠ å¯¹é¢„æœŸæ•ˆæœçš„å®½æ¾åŒ¹é…å¤„ç†
                elif 'é¢„æœŸæ•ˆæœ' in part and not any(keyword in part for keyword in ['1. æ™ºèƒ½è¯Šæ–­', '2. æ™ºèƒ½ä¼˜åŒ–å»ºè®®', '4. é¢„æœŸæ•ˆæœ', '5. ', '6. ']):
                    # å¤„ç†åŒ…å«é¢„æœŸæ•ˆæœä½†æ²¡æœ‰æ ‡å‡†ç¼–å·çš„éƒ¨åˆ†
                    effect_title = self.document.add_paragraph()
                    effect_title_run = effect_title.add_run('ğŸš€ é¢„æœŸæ•ˆæœ:')
                    effect_title_run.bold = True
                    effect_title_run.font.name = 'å¾®è½¯é›…é»‘'
                    effect_title_run.font.size = Pt(11)
                    effect_title_run.font.color.rgb = RGBColor(0, 0, 192)  # è“è‰²æ•ˆæœæ ‡é¢˜
                    
                    # ç§»é™¤é¢„æœŸæ•ˆæœå…³é”®è¯åŠç›¸å…³å†…å®¹
                    content = re.sub(r'.*é¢„æœŸæ•ˆæœ[:ï¼š]?\s*', '', part, count=1)
                    if content.strip():
                        effect_content = self.document.add_paragraph()
                        effect_content_run = effect_content.add_run(content)
                        effect_content_run.font.name = 'å®‹ä½“'
                        effect_content_run.font.size = Pt(10.5)
                        effect_content_run.font.color.rgb = RGBColor(0, 0, 192)  # è“è‰²æ•ˆæœæ–‡æœ¬
                        effect_content.paragraph_format.left_indent = Pt(15)
            
            # æ·»åŠ ç©ºè¡Œå’Œåˆ†éš”çº¿
            self._add_separator_line()
    
    def _generate_summary_and_recommendations(self):
        """ç”Ÿæˆæ€»ç»“å’Œå»ºè®®ï¼ˆåŒ…è£…æ–¹æ³•ï¼Œè°ƒç”¨æ–°æ¨¡å—ï¼‰"""
        summary_gen = SummaryGenerator(
            document=self.document,
            analysis_data=self.analysis_data,
            compare_data=self.compare_data
        )
        summary_gen.generate_summary_and_recommendations()
    
    def _generate_report_footer(self):
        """ç”ŸæˆæŠ¥å‘Šé¡µè„š"""
        # æ·»åŠ ç©ºè¡Œ
        self.document.add_paragraph()
        
        # æ·»åŠ æœ€ç»ˆé¡µè„š
        footer = self.document.add_paragraph()
        footer.alignment = WD_ALIGN_PARAGRAPH.CENTER
        footer_run = footer.add_run("*æœ¬æŠ¥å‘Šç”±æ•°æ®åº“æ™ºèƒ½ä¼˜åŒ–ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒ*")
        footer_run.font.name = 'å®‹ä½“'
        footer_run.font.size = Pt(9)
        footer_run.font.color.rgb = RGBColor(128, 128, 128)
        
        # æ·»åŠ ç”Ÿæˆæ—¥æœŸå’Œæ—¶é—´
        footer_date = self.document.add_paragraph()
        footer_date.alignment = WD_ALIGN_PARAGRAPH.CENTER
        footer_date_run = footer_date.add_run(f"ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        footer_date_run.font.name = 'å®‹ä½“'
        footer_date_run.font.size = Pt(9)
        footer_date_run.font.color.rgb = RGBColor(128, 128, 128)
        
        # æ·»åŠ é¡µç 
        sections = self.document.sections
        for section in sections:
            # æ·»åŠ é¡µè„š
            footer = section.footer
            # ç¡®ä¿é¡µè„šæœ‰æ®µè½
            if not footer.paragraphs:
                paragraph = footer.add_paragraph()
            else:
                paragraph = footer.paragraphs[0]
            paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            
            # æ·»åŠ é¡µç å­—æ®µ - ä½¿ç”¨PAGEå­—æ®µï¼Œåªæ˜¾ç¤ºå½“å‰é¡µç 
            run = paragraph.add_run("ç¬¬ ")
            run.font.name = 'å®‹ä½“'
            run.font.size = Pt(9)
            
            # æ’å…¥PAGEå­—æ®µ - ä½¿ç”¨Wordå­—æ®µæ–¹å¼
            from docx.oxml.shared import OxmlElement, qn
            page_run = paragraph.add_run()
            page_run.font.name = 'å®‹ä½“'
            page_run.font.size = Pt(9)
            
            # æ·»åŠ é¡µç å­—æ®µï¼ŒWordä¼šè‡ªåŠ¨æ›¿æ¢ä¸ºå®é™…é¡µç 
            fldChar1 = OxmlElement('w:fldChar')
            fldChar1.set(qn('w:fldCharType'), 'begin')
            
            instrText = OxmlElement('w:instrText')
            instrText.set(qn('xml:space'), 'preserve')
            instrText.text = 'PAGE'
            
            fldChar2 = OxmlElement('w:fldChar')
            fldChar2.set(qn('w:fldCharType'), 'end')
            
            page_run._r.append(fldChar1)
            page_run._r.append(instrText)
            page_run._r.append(fldChar2)
            
            run = paragraph.add_run(" é¡µ")
            run.font.name = 'å®‹ä½“'
            run.font.size = Pt(9)

# æ·»åŠ ç¼ºå°‘çš„import
import re

def load_db_config(config_file: str = 'db_config.json') -> Optional[Dict]:
    """
    ä»é…ç½®æ–‡ä»¶åŠ è½½æ•°æ®åº“é…ç½®
    æ”¯æŒå¤„ç†å•é…ç½®å¯¹è±¡æˆ–é…ç½®æ•°ç»„
    
    Args:
        config_file: é…ç½®æ–‡ä»¶è·¯å¾„
    
    Returns:
        æ•°æ®åº“é…ç½®å­—å…¸ï¼Œå¦‚æœåŠ è½½å¤±è´¥è¿”å›None
    """
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            config_data = json.load(f)
            
            # å¤„ç†é…ç½®æ•°ç»„æ ¼å¼
            if isinstance(config_data, list):
                # å¦‚æœæ˜¯æ•°ç»„ï¼Œå–ç¬¬ä¸€ä¸ªé…ç½®é¡¹ä½œä¸ºé»˜è®¤é…ç½®
                if not config_data:
                    print(f"âŒ é…ç½®æ–‡ä»¶ä¸­æ²¡æœ‰é…ç½®é¡¹")
                    return None
                config = config_data[0]
                print(f"âš ï¸  æ£€æµ‹åˆ°é…ç½®æ•°ç»„ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªé…ç½®é¡¹")
            else:
                config = config_data
            
            # éªŒè¯å¿…è¦çš„é…ç½®é¡¹
            required_fields = ['host', 'user', 'password']
            for field in required_fields:
                if field not in config:
                    print(f"âŒ é…ç½®æ–‡ä»¶ç¼ºå°‘å¿…è¦é¡¹: {field}")
                    return None
            
            # æ·»åŠ æ…¢æŸ¥è¯¢åˆ†æé»˜è®¤å‚æ•°
            config.setdefault('table', 's')  # é»˜è®¤æ…¢æŸ¥è¯¢è¡¨å
            config.setdefault('port', 3306)  # é»˜è®¤ç«¯å£
            
            return config
    except FileNotFoundError:
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        return None
    except json.JSONDecodeError:
        print(f"âŒ é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {config_file}")
        return None

def main():
    """ä¸»å‡½æ•°"""
    print("=== æ•°æ®åº“æ™ºèƒ½ä¼˜åŒ–åˆ†ææŠ¥å‘Šç”Ÿæˆå™¨ ===")    
    try:
        # å°è¯•åŠ è½½æ•°æ®åº“é…ç½®
        default_db_config = load_db_config()
        
        # ä½¿ç”¨å®æ—¶åˆ†ææ¨¡å¼ï¼Œè¿æ¥åˆ°å®é™…æ•°æ®åº“
        use_live_analysis = True
        slow_query_db_config = None
        
        # è®¾ç½®é»˜è®¤çš„è¿‡æ»¤å‚æ•°
        min_execute_cnt = 1000
        min_query_time = 10.0
        
        print("ğŸ“Š æ…¢æŸ¥è¯¢åˆ†æé…ç½®")
        print("------------------")
        
        if default_db_config:
            # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æ•°æ®åº“è¿æ¥ä¿¡æ¯
            slow_query_db_config = default_db_config
            # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„æ…¢æŸ¥è¯¢è¡¨å
            if 'table' not in slow_query_db_config or slow_query_db_config['table'] == 's':
                slow_query_db_config['table'] = 'slow'
                print("âš ï¸ å·²è‡ªåŠ¨ä¿®æ­£æ…¢æŸ¥è¯¢è¡¨åä¸º 'slow'")
            print("âœ“ ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æ•°æ®åº“è¿æ¥ä¿¡æ¯")
        else:
            # ä½¿ç”¨é»˜è®¤çš„è¿æ¥é…ç½®
            print("âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨æˆ–æ ¼å¼é”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤æ•°æ®åº“è¿æ¥é…ç½®")
            slow_query_db_config = {
                'host': '127.0.0.1',
                'port': 3306,
                'user': 'test',
                'password': 'test',
                'database': 't',
                'table': 'slow'  # ä½¿ç”¨æ­£ç¡®çš„æ…¢æŸ¥è¯¢è¡¨å
            }
            print(f"âœ“ ä½¿ç”¨é»˜è®¤è¿æ¥é…ç½®: host={slow_query_db_config['host']}, port={slow_query_db_config['port']}")
            print(f"âœ“ é»˜è®¤æ…¢æŸ¥è¯¢è¡¨å: {slow_query_db_config['table']}")
        
        # æ‰“å°è¿‡æ»¤å‚æ•°
        print("\nğŸ” æ…¢æŸ¥è¯¢è¿‡æ»¤æ¡ä»¶")
        print("------------------")
        print(f"âœ“ è¿‡æ»¤æ¡ä»¶: æ‰§è¡Œæ¬¡æ•°â‰¥{min_execute_cnt}, æŸ¥è¯¢æ—¶é—´â‰¥{min_query_time}ç§’ (ts_cnt > 1000, query_time_max > 10)")
        
        # åˆ›å»ºæŠ¥å‘Šç”Ÿæˆå™¨
        import logging
        logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        logger = logging.getLogger(__name__)
        logger.info("ğŸ“ˆ æ­£åœ¨æ‰§è¡Œå®æ—¶æ…¢æŸ¥è¯¢åˆ†æä¸å¯¹æ¯”åˆ†æ...")
        report = DatabaseOptimizationReport(
            use_live_analysis=use_live_analysis,
            slow_query_db_config=slow_query_db_config,
            min_execute_cnt=min_execute_cnt,
            min_query_time=min_query_time
        )
        
        # æ£€æŸ¥æ˜¯å¦æˆåŠŸè·å–äº†åˆ†ææ•°æ®
        if not report.analysis_data:
            print("\nâŒ é”™è¯¯ï¼šæ— æ³•è·å–çœŸå®çš„åˆ†ææ•°æ®")
            print("   å¯èƒ½åŸå› ï¼š")
            print("   1. æ•°æ®åº“è¿æ¥å¤±è´¥")
            print("   2. æ…¢æŸ¥è¯¢è¡¨ä¸å­˜åœ¨æˆ–ä¸ºç©º")
            print("   3. æ²¡æœ‰ç¬¦åˆè¿‡æ»¤æ¡ä»¶çš„æ…¢æŸ¥è¯¢è®°å½•")
            print("   4. åˆ†ææ•°æ®æ–‡ä»¶ä¸å­˜åœ¨æˆ–æ ¼å¼é”™è¯¯")
            print("\n   è¯·ç¡®ä¿ï¼š")
            print("   1. æ•°æ®åº“è¿æ¥é…ç½®æ­£ç¡®")
            print("   2. æ…¢æŸ¥è¯¢è¡¨ä¸­æœ‰æ•°æ®")
            print("   3. åˆ†ææ•°æ®æ–‡ä»¶å­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®")
            print("\n   ç¨‹åºå°†é€€å‡ºï¼Œè¯·æ£€æŸ¥ä»¥ä¸Šé—®é¢˜åé‡æ–°è¿è¡Œ")
            return 1
        
        # ç”ŸæˆæŠ¥å‘Š
        print("\nğŸ“ æ­£åœ¨ç”Ÿæˆä¼˜åŒ–åˆ†ææŠ¥å‘Š...")
        output_file = report.create_report()
        
        print("")
        print(f"âœ… æ•°æ®åº“æ™ºèƒ½ä¼˜åŒ–åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {output_file}")
        print(f"ğŸ“„ æ–‡ä»¶ä½ç½®: {os.path.abspath(output_file)}")
        
        # æ·»åŠ ç»“æœè¯´æ˜
        if not report.compare_data:
            print("\nğŸ“‹ æŠ¥å‘Šè¯´æ˜ï¼š")
            print("   - æŠ¥å‘Šä¸­åŒ…å«åŸºæœ¬åˆ†æå†…å®¹ï¼Œä½†å¯èƒ½ç¼ºå°‘å®Œæ•´çš„å¯¹æ¯”åˆ†æ")
            print("   - å»ºè®®æ£€æŸ¥æ•°æ®åº“è¿æ¥å’Œæ…¢æŸ¥è¯¢è¡¨é…ç½®")
        
    except KeyboardInterrupt:
        print("\nâŒ æ“ä½œè¢«ç”¨æˆ·ä¸­æ–­")
        return 0
    except ImportError as e:
        print(f"\né”™è¯¯ï¼šç¼ºå°‘å¿…è¦çš„ä¾èµ–åº“ã€‚è¯·å®‰è£… python-docx åº“ï¼š")
        print("pip install python-docx")
        return 1
    except ConnectionError as e:
        print("\nâŒ æ•°æ®åº“è¿æ¥é”™è¯¯")
        print(f"   é”™è¯¯è¯¦æƒ…: {str(e)}")
        print("   è¯·æ£€æŸ¥ä»¥ä¸‹å†…å®¹:")
        print("   1. æ•°æ®åº“æœåŠ¡å™¨æ˜¯å¦è¿è¡Œ")
        print("   2. è¿æ¥é…ç½®æ˜¯å¦æ­£ç¡®")
        print("   3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        return 1
    except Exception as e:
        print(f"\nâŒ ç”ŸæˆæŠ¥å‘Šæ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
        print("   ç¨‹åºå°†ä¼˜é›…é€€å‡º")
        # åªåœ¨è°ƒè¯•æ¨¡å¼ä¸‹æ˜¾ç¤ºè¯¦ç»†å †æ ˆ
        if os.environ.get('DEBUG', 'False').lower() == 'true':
            import traceback
            traceback.print_exc()
        return 1
    
    return 0

if __name__ == "__main__":
    import sys
    sys.exit(main())
